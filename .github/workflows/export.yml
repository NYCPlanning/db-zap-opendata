name: Daily Export

on:
  schedule:
    - cron: 0 0 * * *
  workflow_dispatch:

  
jobs:
  build:
    runs-on: ubuntu-20.04
    env:
      CLIENT_ID: ${{ secrets.CLIENT_ID }}
      SECRET: ${{ secrets.SECRET }}
      TENANT_ID: ${{ secrets.TENANT_ID }}
      ZAP_DOMAIN: ${{ secrets.ZAP_DOMAIN }}
      ZAP_ENGINE: ${{ secrets.ZAP_ENGINE }}
      AWS_S3_ENDPOINT: ${{ secrets.DO_S3_ENDPOINT }}
      AWS_ACCESS_KEY_ID: ${{ secrets.DO_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.DO_SECRET_ACCESS_KEY }}
      AWS_S3_LIBRARY_BUCKET: edm-recipes
      VERSION: $(date +%Y%m%d)
    strategy:
      fail-fast: false
      matrix:
        entity:
          - dcp_projects
          - dcp_projectactions
          - dcp_projectbbls
          - dcp_projectmilestones
          - dcp_projectactionbbls
          - dcp_communityboarddispositions
          - dcp_dcpprojectteams
        open:
          - false
        include:
          - entity: ['dcp_projects', 'dcp_projectbbls']
            open: true

    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: '3.9' 
          
      - name: Install Dependencies
        run: python3 -m pip install .        
          
      - name: Get ${{ matrix.entity }}
        run: python3 -m src.runner ${{ matrix.entity }}
          
      # - name: Set Version info
      #   id: version
      #   run: |
      #     DATE=$(date +%Y%m%d)
      #     echo "::set-output name=version::$DATE"

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@master
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID_DATA_ENGINEERING }}
          service_account_key: ${{ secrets.GCP_GCS_BQ_SA_KEY }}
          export_default_credentials: true
          
      - name: Archive to BigQuery
        env: 
          VERSION: ${{ steps.version.outputs.version }}
        run: ./zap.sh upload ${{ matrix.entity }} $VERSION
      
      - name: Archive to data library - PGdump
        # env: 
        #   VERSION: ${{ steps.version.outputs.version }}
        run: |
          echo "exporting ${{ matrix.entity }}.sql"
          docker run --rm \
            -e AWS_S3_ENDPOINT=AWS_S3_ENDPOINT\
            -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID\
            -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY\
            -e AWS_S3_BUCKET=$AWS_S3_LIBRARY_BUCKET\
            -v $(pwd)/templates:/templates\
            -v $(pwd)/.output:/.output\
            nycplanning/library:ubuntu-01d9e5eddf65dbdea3eb0c500314963b5ec6246a library archive -f /templates/${{ matrix.entity }}.yml -v $VERSION -s -l -o pgdump --compress
          
      - name: Archive to data library - CSV
        # env:
        #   VERSION: ${{ steps.version.outputs.version }}
        run: |
          echo "exporting ${{ matrix.entity }}.csv"
          docker run --rm \
            -e AWS_S3_ENDPOINT=AWS_S3_ENDPOINT\
            -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID\
            -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY\
            -e AWS_S3_BUCKET=$AWS_S3_LIBRARY_BUCKET\
            -v $(pwd)/templates:/templates\
            -v $(pwd)/.output:/.output\
            nycplanning/library:ubuntu-01d9e5eddf65dbdea3eb0c500314963b5ec6246a library archive -f /templates/${{ matrix.entity }}.yml -v $VERSION -s -l -o csv --compress
      
      - name: Export open data to edm-publishing 
      run: |
        if [${{ matrix.open }}]
        then
        ./zap.sh upload_do ${{ matrix.entity }} $VERSION
        fi
    